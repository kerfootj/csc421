{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC421 Assignment 4 - Part I Discrete Bayesian Networks (5 points) #\n",
    "### Author: George Tzanetakis \n",
    "\n",
    "This notebook is based on the supporting material for topics covered in **Chapter 14 Probabilistic Reasoning** from the book *Artificial Intelligence: A Modern Approach.* \n",
    "\n",
    "This part relies on the provided notebook code probability.ipynb \n",
    "\n",
    "```\n",
    "Misunderstanding of probability may be the greatest of all impediments\n",
    "to scientific literacy.\n",
    "\n",
    "Gould, Stephen Jay\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probability import *\n",
    "from utils import print_table\n",
    "from notebook import psource, pseudocode, heatmap\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In this part of assignment 4 we will be exploring Discrete Bayesian Networks (DBNs) and answering queries with exact and approximate inference methods. We will be using the following network: \n",
    "\n",
    "<img src=\"dispnea.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1A (Minimum) CSC421 -  (1 point, CSC581C - 0 points) \n",
    "\n",
    "Using the convetions for DBNs used in probability.ipynb (from the AIMA authors) encode the diapnea network shown above. Once you have constructed the Bayesian network display the cpt for the Lung Cancer Node (using the API provided not just showing the numbers). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(True,): 0.1, (False,): 0.01}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyspnea = BayesNet([\n",
    "    ('Asia', '', 0.01),\n",
    "    ('Smoker', '', 0.5),\n",
    "    ('TB', ['Asia'], {True: 0.05, False: 0.01}),\n",
    "    ('Cancer', ['Smoker'], {True: 0.1, False: 0.01}),\n",
    "    ('Bronchitis', ['Smoker'], {True: 0.6, False: 0.03}),\n",
    "    ('Either', ['TB', 'Cancer'], {(True, True): 1, (True, False): 1, (False, True): 1, (False, False): 0}),\n",
    "    ('Xray', ['Either'], {True: 0.98, False: 0.05}),\n",
    "    ('Dyspnea', ['Either', 'Bronchitis'], {(True, True): 0.9, (True, False): 0.7, (False, True): 0.8, (False, False): 0.1})\n",
    "])\n",
    "\n",
    "dyspnea.variable_node('Cancer').cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1B (Minimum) (CSC421 - 1 point, CSC581C - 0 point) \n",
    "\n",
    "Answer using exact inference with enumeration the following query: given that a\n",
    "patient has been in Asia and has a positive xray, what is the likelihood of having dyspnea?\n",
    "\n",
    "Write down using markdown the expression that corresponds to this query and the corresponding \n",
    "numbers from the CPT. Calculate the result using a calculator. \n",
    "\n",
    "Write code for the same query using *enumeration_ask* and confirm that the result is the same for the same query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(Dyspnea|Asia,Xray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396226028223374"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumeration_ask('Dyspnea', {'Asia': True, 'Xray': True}, dyspnea)[True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1C (Expected) 1 point \n",
    "\n",
    "Answer using variable elimination i.e the function *elimination_ask*  using the same query. Compare the timing using %%timeit the query using *enumeration_ask* and *eliimination_ask*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396226028223374"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elimination_ask('Dyspnea', {'Asia': True, 'Xray': True}, dyspnea)[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enumeration: 0.0020841000000473286\n",
      "elimination: 0.004639200000042365\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "enumeration_ask('Dyspnea', {'Asia': True, 'Xray': True}, dyspnea)[True]\n",
    "end = timer()\n",
    "print(f'enumeration: {end - start}')\n",
    "\n",
    "start = timer()\n",
    "elimination_ask('Dyspnea', {'Asia': True, 'Xray': True}, dyspnea)[True]\n",
    "end = timer()\n",
    "print(f'elimination: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4.1D (Expected ) 1 point\n",
    "\n",
    "Answer using approximate inference the same query using both rejection sampling and likelihood weighting. Compare the runtime of the two approximate inference algorithms and the two exact inference algorithms for this query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejection sampling: 0.12401279999994586\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "rejection_sampling('Dyspnea', {'Asia': True, 'Xray': True}, dyspnea)[True]\n",
    "end = timer()\n",
    "print(f'rejection sampling: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood weighting: 0.024634999999989304\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "likelihood_weighting('Dyspnea', {'Asia': True, 'Xray': True}, dyspnea, 2000)[True]\n",
    "end = timer()\n",
    "print(f'likelihood weighting: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastest Algorithms:\n",
    "1. enumeration: 0.0020841000000473286\n",
    "2. elimination: 0.004639200000042365\n",
    "3. likelihood weighting: 0.024634999999989304\n",
    "4. rejection sampling: 0.12401279999994586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4.1E (Advanced) 1 point \n",
    "\n",
    "A Naive Bayes classifier can be considered as a Bayesian Network. The classification problem can then be expressed as setting all the variables corresponding to the features as evidence and querying the probability for the class. Express the Bernoulli Naive Bayes classifier you implemented in the previous assignment as a Bayesian Network using the probability.ipynb conventions. Now that you have a DBN express and solve the classification problem as a query and go over all the previous steps for this particular problem. More specifically do exact inference by enumeration, exact inference by variable elimination, approximate inference by rejection sampling and approximate inference by likelihood weighting to answer the query and show the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enumeration_ask\n",
      "Positive (Great, Hilarious): 0.7722557297949337\n",
      "Positive (Aweful, Bad): 0.1252466780686752\n",
      "Negative (Great, Hilarious): 0.22774427020506635\n",
      "Negative (Aweful, Bad): 0.8747533219313248\n",
      "\n",
      "elimination_ask\n",
      "Positive (Great, Hilarious): 0.7722557297949337\n",
      "Positive (Aweful, Bad): 0.1252466780686752\n",
      "Negative (Great, Hilarious): 0.22774427020506635\n",
      "Negative (Aweful, Bad): 0.8747533219313248\n",
      "\n",
      "rejection_sampling\n",
      "Positive (Great, Hilarious): 0.7751196172248804\n",
      "Positive (Aweful, Bad): 0.1746987951807229\n",
      "Negative (Great, Hilarious): 0.22026431718061673\n",
      "Negative (Aweful, Bad): 0.8873873873873874\n",
      "\n",
      "likelihood_weighting\n",
      "Positive (Great, Hilarious): 0.7700235141288507\n",
      "Positive (Aweful, Bad): 0.1253805393908918\n",
      "Negative (Great, Hilarious): 0.2310604322888647\n",
      "Negative (Aweful, Bad): 0.8752757621931632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# polarity      awful    bad    boring    dull    effective    enjoyable    great    hilarious\n",
    "# ----------  -------  -----  --------  ------  -----------  -----------  -------  -----------\n",
    "# pos           0.034  0.28      0.054   0.025        0.154        0.096    0.485        0.132\n",
    "# neg           0.122  0.545     0.175   0.101        0.086        0.054    0.32         0.059\n",
    "\n",
    "review = BayesNet([\n",
    "    ('Positive', '', 0.5),\n",
    "    ('Negative', '', 0.5),\n",
    "    ('Aweful', ['Positive', 'Negative'], {(True, True): 0.0, (True, False): 0.034, (False, True): 0.122, (False, False): 0.0}),\n",
    "    ('Bad', ['Positive', 'Negative'], {(True, True): 0.0, (True, False): 0.28, (False, True): 0.545, (False, False): 0.0}),\n",
    "    ('Boring', ['Positive', 'Negative'], {(True, True): 0.0, (True, False): 0.054, (False, True): 0.175, (False, False): 0.0}),\n",
    "    ('Dull', ['Positive', 'Negative'], {(True, True): 0.0, (True, False): 0.025, (False, True): 0.101, (False, False): 0.0}),\n",
    "    ('Effective', ['Positive', 'Negative'], {(True, True): 0.0, (True, False): 0.154, (False, True): 0.086, (False, False): 0.0}),\n",
    "    ('Enjoyable', ['Positive', 'Negative'], {(True, True): 0.0, (True, False): 0.096, (False, True): 0.054, (False, False): 0.0}),\n",
    "    ('Great', ['Positive', 'Negative'], {(True, True): 0.0, (True, False): 0.485, (False, True): 0.32, (False, False): 0.0}),\n",
    "    ('Hilarious', ['Positive', 'Negative'], {(True, True): 0.0, (True, False): 0.132, (False, True): 0.059, (False, False): 0.0}),\n",
    "])\n",
    "\n",
    "for method in [enumeration_ask, elimination_ask, rejection_sampling, likelihood_weighting]:\n",
    "    print(method.__name__)\n",
    "    print(f'Positive (Great, Hilarious): {method(\"Positive\", {\"Great\": True, \"Hilarious\": True}, review)[True]}')\n",
    "    print(f'Positive (Aweful, Bad): {method(\"Positive\", {\"Aweful\": True, \"Bad\": True}, review)[True]}')\n",
    "    print(f'Negative (Great, Hilarious): {method(\"Negative\", {\"Great\": True, \"Hilarious\": True}, review)[True]}')\n",
    "    print(f'Negative (Aweful, Bad): {method(\"Negative\", {\"Aweful\": True, \"Bad\": True}, review)[True]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4.1F (ADVANCED) (CSC421 - 0 points, CSC581C - 1 point)\n",
    "\n",
    "This question requires that you have completed the previous question 4.1E. Do a comparison of the 4 inference algorithms on DBNs as well as the standard Bernoulli Naive Bayes classifier you implemented in assignment 3 in terms of two aspects: classification accuracy and run-time. For both classification accuracy and run-time comparison using %%timeit use the training set of positive and negative reviews for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4.1G (ADVANCED) (CSC421 - 0 points, CSC581C - 1 point)\n",
    "\n",
    "Encode both the Dispnea DBN and the Naive Bayes Network from the previous question as DBNs using the *pgmpy* package for Probablistic Graphical Models in Python. Answer the same queries you did above using variable elimination. \n",
    "\n",
    "http://pgmpy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
