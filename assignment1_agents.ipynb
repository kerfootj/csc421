{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC421 Assignment 1 Agents #\n",
    "\n",
    "This notebook is based on the supporting material for topics covered in **Chapter 2 - Intelligent Agents** from the book *Artificial Intelligence: A Modern Approach.* This notebook uses implementations from [agents.py](https://github.com/aimacode/aima-python/blob/master/agents.py) module. Let's start by importing everything from agents module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import *\n",
    "from notebook import psource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENVIRONMENT - Park\n",
    "\n",
    "A park is an example of an environment because our dog can perceive and act upon it. The <b>Environment</b> class is an abstract class, so we will have to create our own subclass from it before we can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Food(Thing):\n",
    "    pass\n",
    "\n",
    "class Water(Thing):\n",
    "    pass\n",
    "\n",
    "class ParkOrig(Environment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"move down\":\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.movedown()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]): #Have the dog eat the first item\n",
    "                    print('{} ate {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "            \n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1A (Minimum) 0.5 points \n",
    "\n",
    "Copy the code above and modify the provided park environment so that instead of Food there are two more \"things\" called Tree and StainedTree. Replace the eat action action with one called mark that checks to see if there is a Tree at the agent's location and if there is one it changes it to a StainedTree at the same location. You can add a thing to a particular location with self.add_thing(t, location). Also change the is_done() method to stop the simulation when there are no Trees left to stain. Also move all agents to location 0 when the simulation is done. In addition, add a method to Park called show() that prints all locations up to a max_location. Example output would be: \n",
    "\n",
    "```python\n",
    "park.show(5)\n",
    "park.run(1)\n",
    "park.show(5) \n",
    "\n",
    "0:[]\n",
    "1:[<BlindDog>]\n",
    "2:[]\n",
    "3:[]\n",
    "4:[]\n",
    "BlindDog decided to move down at location: 1\n",
    "0:[]\n",
    "1:[]\n",
    "2:[<BlindDog>]\n",
    "3:[]\n",
    "4:[]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER \n",
    "class Tree(Thing):\n",
    "    pass\n",
    "\n",
    "class StainedTree(Thing):\n",
    "    pass\n",
    "\n",
    "class Water(Thing):\n",
    "    pass\n",
    "\n",
    "class Park(Environment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"move down\":\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.movedown()\n",
    "        elif action == \"mark\":\n",
    "            items = self.list_things_at(agent.location, tclass=Tree)\n",
    "            if len(items) != 0:\n",
    "                if agent.mark(items[0]):\n",
    "                    print('{} marked {} at location: {}'\n",
    "                        .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0])\n",
    "                    self.add_thing(StainedTree(), agent.location)\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "            \n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_trees = not any(isinstance(thing, Tree) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        \n",
    "        done = dead_agents or no_trees\n",
    "        \n",
    "        if done:\n",
    "            for agent in self.agents:\n",
    "                agent.location = 0\n",
    "            \n",
    "        return done\n",
    "    \n",
    "    def show(self, num):\n",
    "        for i in range(0, num):\n",
    "            print('{}:{}'.format(i, self.list_things_at(i)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROGRAM - BlindDog\n",
    "Now that we have a <b>Park</b> Class, we re-implement our <b>BlindDog</b> to be able to move down and eat food or drink water only if it is present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlindDogOrig(Agent):\n",
    "    location = 1\n",
    "    \n",
    "    def movedown(self):\n",
    "        self.location += 1\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1B (Minimum) 0.5 points \n",
    "\n",
    "Now its time to re-implement a <b>program</b> module for our dog that likes to mark. A program controls how the dog acts upon its environment. Our program will be very simple, and is shown in the table below. Change the code above to reflect this new program in which if there is no tree or water then the Blind Dog moves down, if there is water the Blind Dog drinks it, and if there is a tree, the dogs marks it by making it a Stained tree. \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Tree</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>mark</td>\n",
    "       <td>move down</td>\n",
    "   </tr>\n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER \n",
    "class BlindDog(Agent):\n",
    "    location = 1\n",
    "    \n",
    "    def movedown(self):\n",
    "        self.location += 1\n",
    "        \n",
    "    def mark(self, thing):\n",
    "        if isinstance(thing, Tree):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "def program(percepts):\n",
    "    '''Returns an action based on the dog's percepts'''\n",
    "    for p in percepts:\n",
    "        if isinstance(p, Tree):\n",
    "            return 'mark'\n",
    "        elif isinstance(p, Water):\n",
    "            return 'drink'\n",
    "    return 'move down'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run our simulation by creating a park with some food, water, and our dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[]\n",
      "1:[<BlindDog>]\n",
      "2:[]\n",
      "3:[]\n",
      "4:[]\n",
      "5:[<Tree>]\n",
      "6:[]\n",
      "7:[<Water>]\n",
      "8:[]\n",
      "9:[<Tree>]\n",
      "BlindDog decided to move down at location: 1\n",
      "BlindDog decided to move down at location: 2\n",
      "BlindDog decided to move down at location: 3\n",
      "BlindDog decided to move down at location: 4\n",
      "BlindDog marked Tree at location: 5\n",
      "BlindDog decided to move down at location: 5\n",
      "0:[]\n",
      "1:[]\n",
      "2:[]\n",
      "3:[]\n",
      "4:[]\n",
      "5:[<StainedTree>]\n",
      "6:[<BlindDog>]\n",
      "7:[<Water>]\n",
      "8:[]\n",
      "9:[<Tree>]\n",
      "BlindDog decided to move down at location: 6\n",
      "BlindDog drank Water at location: 7\n",
      "BlindDog decided to move down at location: 7\n",
      "BlindDog decided to move down at location: 8\n",
      "BlindDog marked Tree at location: 9\n",
      "0:[<BlindDog>]\n",
      "1:[]\n",
      "2:[]\n",
      "3:[]\n",
      "4:[]\n",
      "5:[<StainedTree>]\n",
      "6:[]\n",
      "7:[]\n",
      "8:[]\n",
      "9:[<StainedTree>]\n"
     ]
    }
   ],
   "source": [
    "park = Park()\n",
    "dog = BlindDog(program)\n",
    "tree1 = Tree()\n",
    "tree2 = Tree()\n",
    "water = Water()\n",
    "park.add_thing(dog, 1)\n",
    "park.add_thing(tree1, 5)\n",
    "park.add_thing(water, 7)\n",
    "park.add_thing(tree2, 9)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This should be the final output after running the simulation for \n",
    "enough steps for all the trees to be stained \n",
    "\n",
    "0:[<BlindDog>]\n",
    "1:[]\n",
    "2:[]\n",
    "3:[]\n",
    "4:[]\n",
    "5:[<StainedTree>]\n",
    "6:[]\n",
    "7:[]\n",
    "8:[]\n",
    "9:[<StainedTree>]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "park.show(10)\n",
    "park.run(6)\n",
    "park.show(10)\n",
    "park.run(6)\n",
    "park.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Note how the simulation stopped after the dog marked all trees, as we had defined before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we learnt to implement an agent, its program, and an environment on which it acts. However, this was a very simple case. Let's try to add complexity to it by creating a 2-Dimensional environment!\n",
    "\n",
    "\n",
    "## AGENTS IN A 2D ENVIRONMENT\n",
    "\n",
    "For us to not read so many logs of what our dog did, we add a bit of graphics while making our Park 2D. To do so, we will need to make it a subclass of <b>GraphicEnvironment</b> instead of Environment. Parks implemented by subclassing <b>GraphicEnvironment</b> class adds these extra properties to it:\n",
    "\n",
    " - Our park is indexed in the 4th quadrant of the X-Y plane.\n",
    " - Every time we create a park subclassing <b>GraphicEnvironment</b>, we need to define the colors of all the things we plan to put into the park. The colors are defined in typical [<b>RGB digital 8-bit format</b>](https://en.wikipedia.org/wiki/RGB_color_model#Numeric_representations), common across the web.\n",
    " - Fences are added automatically to all parks so that our dog does not go outside the park's boundary - it just isn't safe for blind dogs to be outside the park by themselves! <b>GraphicEnvironment</b> provides `is_inbounds` function to check if our dog tries to leave the park.\n",
    " \n",
    "First let us try to upgrade our 1-dimensional `Park` environment by just replacing its superclass by `GraphicEnvironment`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Park2DOrig(GraphicEnvironment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"move down\":\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.movedown()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]): #Have the dog eat the first item\n",
    "                    print('{} ate {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "\n",
    "class BlindDogOrig(Agent):\n",
    "    location = [0,1] # change location to a 2d value\n",
    "    direction = Direction(\"down\") # variable to store the direction our dog is facing\n",
    "    \n",
    "    def movedown(self):\n",
    "        self.location[1] += 1\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1C (Expected) 0.5 points \n",
    "\n",
    "Modify the ParkDOrig and BlindDogOrig code above to support the mark action in two dimensions. **NOTE** The agent location is represented as a list so be careful about how you handle assignments which in Python by default sets \n",
    "two variables pointing to the same list. Change the isDone method so that the simulation stops when there are no trees left to mark and return agents to the start location. Also add a show method for printing the contents of the park - you can use self.width and self.height for the park dimensions. It is not required but it is a good idea to look at the contents of agents.py and understand how things are working under the hood. \n",
    "\n",
    "**NOTE** You will need to edit agents.py in a small way: \n",
    "Change the is_inbounds() method to: \n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "    def is_inbounds(self, location):\n",
    "        # Checks to make sure that the location is inbounds (within walls if we have walls)\n",
    "        x, y = location\n",
    "        return not (x < self.x_start or x >= self.x_end or y < self.y_start or y >= self.y_end)\n",
    "```\n",
    "This fixes a small bug that allowed the agent to be outiside the park at x_end or y_yend coordinates \n",
    "probably by mixing indexing from 0 and indexing from 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER \n",
    "class Park2D(GraphicEnvironment):\n",
    "    def percept(self, agent):\n",
    "        '''return a list of things that are in our agent's location'''\n",
    "        things = self.list_things_at(agent.location)\n",
    "        return things\n",
    "    \n",
    "    def execute_action(self, agent, action):\n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"move down\":\n",
    "            print('{} decided to {} at location: {}'.format(str(agent)[1:-1], action, agent.location))\n",
    "            agent.movedown()\n",
    "        elif action == \"eat\":\n",
    "            items = self.list_things_at(agent.location, tclass=Food)\n",
    "            if len(items) != 0:\n",
    "                if agent.eat(items[0]): #Have the dog eat the first item\n",
    "                    print('{} ate {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "        elif action == \"drink\":\n",
    "            items = self.list_things_at(agent.location, tclass=Water)\n",
    "            if len(items) != 0:\n",
    "                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "                    print('{} drank {} at location: {}'\n",
    "                          .format(str(agent)[1:-1], str(items[0])[1:-1], agent.location))\n",
    "                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "    def is_done(self):\n",
    "        '''By default, we're done when we can't find a live agent, \n",
    "        but to prevent killing our cute dog, we will stop before itself - when there is no more food or water'''\n",
    "        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_edibles\n",
    "\n",
    "class BlindDog(Agent):\n",
    "    location = [0,1] # change location to a 2d value\n",
    "    direction = Direction(\"down\") # variable to store the direction our dog is facing\n",
    "    \n",
    "    def movedown(self):\n",
    "        self.location[1] += 1\n",
    "        \n",
    "    def eat(self, thing):\n",
    "        '''returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Food):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def drink(self, thing):\n",
    "        ''' returns True upon success or False otherwise'''\n",
    "        if isinstance(thing, Water):\n",
    "            return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test this new park with our same dog, food and water. We color our dog with a nice red and mark trees and water with orange and blue respectively. In addition, we color Stained trees yellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park2D(5,20, color={'BlindDog': (200,0,0), 'Water': (0, 200, 200), 'StainedTree':(255,255,0),'Tree': (230, 115, 40)}) # park width is set to 5, and height to 20\n",
    "dog = BlindDog(program)\n",
    "tree = Tree()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,1])\n",
    "park.add_thing(tree, [0,5])\n",
    "park.add_thing(water, [0,7])\n",
    "tree2 = Tree()\n",
    "park.add_thing(tree2, [0,9])\n",
    "\n",
    "park.run(6)\n",
    "park.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.run(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding some graphics was a good idea! We immediately see that the code works, but our blind dog doesn't make any use of the 2 dimensional space available to him. Let's make our dog more energetic so that he turns and moves forward, instead of always moving down. In doing so, we'll also need to make some changes to our environment to be able to handle this extra motion.\n",
    "\n",
    "### PROGRAM - EnergeticBlindDog\n",
    "\n",
    "Let's make our dog turn or move forwards at random - except when he's at the edge of our park - in which case we make him change his direction explicitly by turning to avoid trying to leave the park. However, our dog is blind so he wouldn't know which way to turn - he'd just have to try arbitrarily.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Water</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>drink</td>\n",
    "       <td>\n",
    "       <table>\n",
    "           <tr>\n",
    "               <td><b>Remember being at Edge : </b></td>\n",
    "               <td>At Edge</td>\n",
    "               <td>Not at Edge</td>\n",
    "           </tr>\n",
    "           <tr>\n",
    "               <td><b>Action : </b></td>\n",
    "               <td>Turn Left / Turn Right <br> ( 50% - 50% chance )</td>\n",
    "               <td>Turn Left / Turn Right / Move Forward <br> ( 25% - 25% - 50% chance )</td>\n",
    "           </tr>\n",
    "       </table>\n",
    "       </td>\n",
    "   </tr>\n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1D (Expected) 0.5 points \n",
    "\n",
    "In this question I ask you to add some logging to the park and change the BlindDog from a reflex-agent to a very simple model-based agent. First you will need to modify EnergeticBlindDog from the agents.ipynb notebook \n",
    "similarly to how we did above to support marking trees. For measuring the performance of our agent we can count the number of steps that are required to mark all the trees. As the agent behaves stochastically this number will vary. You can initialize the number of steps in the Park environment by adding an appropriate __init__ function. \n",
    "You will need to modify is_done appropriately so that it keeps track of the number steps and print the final number of steps when the simulation is completed. \n",
    "\n",
    "```Python\n",
    "def __init__(self, width=10, height=10, boundary=True, color={}, display=False):\n",
    "     super().__init__(width, height, boundary, color, display)\n",
    "     self.steps = 0 \n",
    "        \n",
    "```\n",
    "\n",
    "\n",
    "The program of an Agent is a function that takes as input a list of percepts and \n",
    "returns an action. In order to create a model agent we have to maintain some state information. \n",
    "There is different ways to achieve this effect in Python. Here is an example \n",
    "of wrapping the program into a callable class i.e a class that can be called as a function. \n",
    "Here is an example of a Program that keeps track of whether the agent has drank water or not. \n",
    "\n",
    "Write a similar CountMarkingProgram that counts how many trees have been marked by the Agent. \n",
    "It is important to understand that the only way the agent can experience the environment \n",
    "is through the precepts. It would be easy to track the information about how many trees \n",
    "have been marked in the Environment and inform the agent BUT that would completely break \n",
    "the restriction that the Agent ONLY experiences the world through the precepts. \n",
    "\n",
    "\n",
    "```Python\n",
    "class ThirstyProgram:\n",
    "\n",
    "    def __init__(self): \n",
    "        self.thirsty = True \n",
    "    \n",
    "    def program(self,percepts):\n",
    "        '''Returns an action based on it's percepts'''\n",
    "        print('Thirsty = ', self.thirsty)\n",
    "        for p in percepts: # first eat or drink - you're a dog!\n",
    "            if isinstance(p, Tree):\n",
    "                return 'mark'\n",
    "            elif isinstance(p, Water):\n",
    "                self.thirsty = False \n",
    "                return 'drink'\n",
    "            if isinstance(p,Bump): # then check if you are at an edge and have to turn\n",
    "                turn = False\n",
    "                choice = random.choice((1,2));\n",
    "            else:\n",
    "                choice = random.choice((1,2,3,4)) # 1-right, 2-left, others-forward\n",
    "        if choice == 1:\n",
    "            return 'turnright'\n",
    "        elif choice == 2:\n",
    "            return 'turnleft'\n",
    "        else:\n",
    "            return 'moveforward'\n",
    "    \n",
    "    def __call__(self, precepts): \n",
    "        return self.program(precepts)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENVIRONMENT - Park2D\n",
    "\n",
    "We also need to modify our park accordingly, in order to be able to handle all the new actions our dog wishes to execute. Additionally, we'll need to prevent our dog from moving to locations beyond our park boundary - it just isn't safe for blind dogs to be outside the park by themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our park is ready for the 2D motion of our energetic dog, lets test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park = Park2D(5,5, color={'EnergeticBlindDog': (200,0,0), 'Water': (0, 200, 200), 'Tree': (230, 115, 40),\n",
    "             'StainedTree': (255, 255,0)})\n",
    "dog = EnergeticBlindDog(program)\n",
    "tree = Tree()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,0])\n",
    "park.add_thing(tree, [1,2])\n",
    "park.add_thing(water, [0,1])\n",
    "morewater = Water()\n",
    "anothertree = Tree()\n",
    "park.add_thing(morewater, [2,4])\n",
    "park.add_thing(anothertree, [4,3])\n",
    "print(\"dog started at [0,0], facing down. Let's see if he found any food or water!\")\n",
    "\n",
    "# this should run until the simulation is done. The two trees should be stained and \n",
    "# the dog should be at [0,0]\n",
    "\n",
    "showGUI = False\n",
    "if (showGUI): \n",
    "    park.run()\n",
    "else: \n",
    "    while not(park.is_done()): \n",
    "        park.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "park = Park2D(5,5, color={'EnergeticBlindDog': (200,0,0), 'Water': (0, 200, 200), 'Tree': (230, 115, 40),\n",
    "             'StainedTree': (255, 255,0)})\n",
    "dog = EnergeticBlindDog(ThirstyProgram())\n",
    "tree = Tree()\n",
    "water = Water()\n",
    "park.add_thing(dog, [0,0])\n",
    "park.add_thing(tree, [1,2])\n",
    "park.add_thing(water, [0,1])\n",
    "morewater = Water()\n",
    "anothertree = Tree()\n",
    "park.add_thing(morewater, [2,4])\n",
    "park.add_thing(anothertree, [4,3])\n",
    "print(\"dog started at [0,0], facing down. Let's see if he found any food or water!\")\n",
    "park.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1E (Advanced)  - no points \n",
    "\n",
    "This question is not going to be graded but gives you some ideas of things to try if you want to explore agents further - the questions are much more open and you would have to refine them:  \n",
    "\n",
    "1. Change the code so that if the dog drinks water it can only mark two trees. After that it can not mark until it drinks water again. \n",
    "\n",
    "2. Have the dog be able to sense the immediate neighbors i.e return any things that are located in the immediate neighborhood. \n",
    "\n",
    "3. Write a program that takes advantage of the sensing information. Show empirically by running multiple simulation runs that the dog that is able to sense performs better (on average finishes the simulation) faster \n",
    "than the energetic blind dog \n",
    "\n",
    "4. Add multiple dogs to the simulation \n",
    "\n",
    "5. Add agents that feed on other agents to model predator/prey interactions \n",
    "\n",
    "6. Write a goal-based agent version of the dog - with the explicit goal of marking every tree in the park \n",
    "\n",
    "7. Write a utility-based agent version of the dog - add complexity to the environment and multiple competing requirements \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
